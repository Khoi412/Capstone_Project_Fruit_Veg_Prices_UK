{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **(ADD THE NOTEBOOK NAME HERE)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Start Stastical testing using the cleaned CSV file in the Processed folder \n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Import Sci-kit learn for Machine Learning/feature engine\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Write here which files, code or artefacts you generate by the end of the notebook \n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* If you have any additional comments that don't fit in the previous bullets, please state them here. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\ngubo\\\\Documents\\\\vscode-projects\\\\Capstone_Project_Fruit_Veg_Prices_UK\\\\jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\ngubo\\\\Documents\\\\vscode-projects\\\\Capstone_Project_Fruit_Veg_Prices_UK'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Section 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numeric columns to impute: ['price']\n",
            "['price']\n",
            "price    float64\n",
            "dtype: object\n",
            "   price\n",
            "0   2.05\n",
            "1   1.22\n",
            "2   1.14\n",
            "3   1.05\n",
            "4   1.03\n",
            "(9256, 1) \n",
            " <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "### Data Cleaning\n",
        "from feature_engine.imputation import MeanMedianImputer\n",
        "\n",
        "### Feat Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "### PCA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "### ML algorithm\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Load the cleaned dataset\n",
        "df = pd.read_csv('Dataset/Processed/fruitvegprices-2017_2022-cleaned.csv')\n",
        "\n",
        "# make sure price (and other numeric columns) are numeric\n",
        "df['price'] = (df['price']\n",
        "               .astype(str)\n",
        "               .str.replace('[Â£,]', '', regex=True)\n",
        "               .replace('', np.nan)\n",
        "               .astype(float))\n",
        "\n",
        "# pick numeric columns to impute\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "print(\"Numeric columns to impute:\", numeric_cols)\n",
        "\n",
        "print(numeric_cols)\n",
        "print(df[numeric_cols].dtypes.head(20))\n",
        "print(df[numeric_cols].head())  # sample values\n",
        "\n",
        "# Canonical PipelineCluster - parameterized and safe (uses numeric_cols)\n",
        "def PipelineCluster(impute_vars=None, n_pca=10, n_clusters=10, add_model=False):\n",
        "    \"\"\"Create a reusable sklearn Pipeline for numeric preprocessing and optional clustering.\n",
        "    The pipeline performs these steps in order:\n",
        "      1. Imputation (median) for the selected numeric variables using Feature-engine's\n",
        "         MeanMedianImputer. This is robust to outliers compared to mean imputation.\n",
        "      2. Standard scaling (zero mean, unit variance) via sklearn's StandardScaler.\n",
        "      3. PCA to reduce dimensionality (n_pca components).\n",
        "      4. Optionally append a KMeans clustering step when add_model=True.\n",
        "    Parameters\n",
        "    ----------\n",
        "    impute_vars : list[str] or None\n",
        "        List of numeric column names to impute. If None, uses the global `numeric_cols`\n",
        "        discovered earlier in the notebook.\n",
        "    n_pca : int\n",
        "        Number of PCA components to keep. It will be capped to the number of features\n",
        "        (minimum 1) to avoid errors.\n",
        "    n_clusters : int\n",
        "        Number of clusters for KMeans when add_model=True.\n",
        "    add_model : bool\n",
        "        If True, the returned pipeline includes a final KMeans estimator; otherwise\n",
        "        the pipeline contains only transformers (imputer, scaler, PCA).\n",
        "    Returns\n",
        "    -------\n",
        "    sklearn.pipeline.Pipeline\n",
        "        A sklearn Pipeline instance ready to fit/transform (or fit_predict if model\n",
        "        step is appended).\n",
        "    \"\"\"\n",
        "    # Default to all numeric columns if user didn't provide a list\n",
        "    if impute_vars is None:\n",
        "        impute_vars = numeric_cols\n",
        "    # Ensure n_pca is at most the number of input features and at least 1\n",
        "    n_pca = min(n_pca, max(1, len(impute_vars)))\n",
        "    # Build transformer steps. Keep names short and explicit for readability.\n",
        "    steps = [\n",
        "        (\"imputer\", MeanMedianImputer(imputation_method='median', variables=impute_vars)),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"pca\", PCA(n_components=n_pca, random_state=0)),\n",
        "    ]\n",
        "    # Optionally add a clustering model at the end of the pipeline\n",
        "    if add_model:\n",
        "        steps.append((\"model\", KMeans(n_clusters=n_clusters, random_state=0)))\n",
        "    pipeline_base = Pipeline(steps)\n",
        "    return pipeline_base\n",
        "\n",
        "# Create pipeline and run PCA on numeric columns (no model by default)\n",
        "pipeline_cluster = PipelineCluster(n_pca=10, n_clusters=10, add_model=False)\n",
        "# keep only the steps up to PCA (exclude model) - this will be correct whether add_model is True or False\n",
        "pipeline_pca = Pipeline(pipeline_cluster.steps[:-1])  # -1 excludes the model only\n",
        "# fit/transform only numeric columns to avoid converting strings to float\n",
        "df_pca = pipeline_pca.fit_transform(df[numeric_cols].copy())\n",
        "\n",
        "print(df_pca.shape, '\\n', type(df_pca))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(9256, 1) \n",
            " <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "# Reuse the canonical PipelineCluster (defined earlier) which supports add_model\n",
        "# Create pipeline and run PCA on numeric columns (no model by default)\n",
        "pipeline_cluster = PipelineCluster(n_pca=10, n_clusters=10, add_model=False)\n",
        "# keep only the steps up to PCA (exclude model) - this will be correct whether add_model is True or False\n",
        "pipeline_pca = Pipeline(pipeline_cluster.steps[:-1])  # -1 excludes the model only\n",
        "# fit/transform only numeric columns to avoid converting strings to float\n",
        "df_pca = pipeline_pca.fit_transform(df[numeric_cols].copy())\n",
        "\n",
        "print(df_pca.shape, '\\n', type(df_pca))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test columns: ['price']\n",
            "X_test_trans shape: (9256, 1)\n",
            "Sample transformed values (first 5 rows):\n",
            "[[ 0.24288433]\n",
            " [-0.18234037]\n",
            " [-0.22332588]\n",
            " [-0.26943458]\n",
            " [-0.27968096]]\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Smoke-test for the preprocessing pipeline.\n",
        "Runs a tiny end-to-end pipeline on a minimal numeric subset so we can:\n",
        "  - verify imputation, scaling and PCA run without errors, and\n",
        "  - inspect the transformed output shape and sample values.\n",
        "This is intentionally small and non-destructive: it copies the test columns\n",
        "and does not modify the main DataFrame.\n",
        "\"\"\"\n",
        "# Choose test columns: prefer 'price' if present, otherwise pick the first numeric\n",
        "test_cols = ['price'] if 'price' in numeric_cols else numeric_cols[:1]\n",
        "print('Test columns:', test_cols)\n",
        "# Build a minimal pipeline with a single PCA component for speed\n",
        "p_test = PipelineCluster(impute_vars=test_cols, n_pca=1)\n",
        "# Prepare data copy and run fit_transform (safe, local to X_test)\n",
        "X_test = df[test_cols].copy()\n",
        "X_test_trans = p_test.fit_transform(X_test)\n",
        "# Report shape and show a small sample of transformed values\n",
        "print('X_test_trans shape:', getattr(X_test_trans, 'shape', None))\n",
        "print('Sample transformed values (first 5 rows):')\n",
        "print(X_test_trans[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ngubo\\Documents\\vscode-projects\\Capstone_Project_Fruit_Veg_Prices_UK\\.venv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assigned cluster labels shape: 9256\n",
            "Cluster label sample (first 20): [0 3 3 3 3 3 3 3 3 3 0 0 3 3 3 3 3 3 3 3]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item</th>\n",
              "      <th>price</th>\n",
              "      <th>cluster_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>apples</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apples</td>\n",
              "      <td>1.22</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>apples</td>\n",
              "      <td>1.14</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>apples</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>apples</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>apples</td>\n",
              "      <td>0.85</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>pears</td>\n",
              "      <td>0.77</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>pears</td>\n",
              "      <td>1.24</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>beetroot</td>\n",
              "      <td>0.52</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>brussels_sprouts</td>\n",
              "      <td>0.78</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               item  price  cluster_label\n",
              "0            apples   2.05              0\n",
              "1            apples   1.22              3\n",
              "2            apples   1.14              3\n",
              "3            apples   1.05              3\n",
              "4            apples   1.03              3\n",
              "5            apples   0.85              3\n",
              "6             pears   0.77              3\n",
              "7             pears   1.24              3\n",
              "8          beetroot   0.52              3\n",
              "9  brussels_sprouts   0.78              3"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Demo: run pipeline including KMeans model on numeric columns (small n_clusters for speed)\n",
        "# Use the PipelineCluster definition from cell 12, which supports add_model\n",
        "# Make sure to use the PipelineCluster from cell 12, not cell 13\n",
        "p_with_model = PipelineCluster(impute_vars=numeric_cols, n_pca=5, n_clusters=5, add_model=True)\n",
        "X_numeric = df[numeric_cols].copy()\n",
        "X_trans_labels = p_with_model.fit_predict(X_numeric)\n",
        "print('Assigned cluster labels shape:', len(X_trans_labels))\n",
        "print('Cluster label sample (first 20):', X_trans_labels[:20])\n",
        "# Attach labels to a small sample dataframe for inspection\n",
        "sample = df.loc[X_numeric.index[:20], :].copy()\n",
        "sample['cluster_label'] = X_trans_labels[:20]\n",
        "sample[['item','price','cluster_label']].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 1 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Section 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 2 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
